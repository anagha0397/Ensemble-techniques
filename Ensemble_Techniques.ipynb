{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86d10ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold          # For getting samples of data\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier      # Base learner will be decision tree\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e659dd38",
   "metadata": {},
   "source": [
    "## Bagging Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d2c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename,names=names)\n",
    "array = dataframe.values\n",
    "x = array[:,0:8]\n",
    "y = array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b62c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits = 10, random_state = 7, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c23a4ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a base learners from sample data\n",
    "cart = DecisionTreeClassifier()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9851d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model using baggingclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b477c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = 150            # Number of decision trees we want to build \n",
    "\n",
    "model = BaggingClassifier(base_estimator = cart, n_estimators = num_trees, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "362045b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuarcy of the model, as number of folds we have considered is 10 so 10 accuracies will be created and at the end average of those will be taken\n",
    "\n",
    "results = cross_val_score(model, x, y, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cb44aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.3021189336979"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the average of all the accuracies\n",
    "\n",
    "results.mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5b3490",
   "metadata": {},
   "source": [
    "Inference: Accuracy depends on the number of trees we mention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5d669",
   "metadata": {},
   "source": [
    "## Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ec72475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold          # For getting samples of data\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47bb2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = array[:,0:8]\n",
    "y = array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "960fe20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits = 10, random_state = 7, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ccfd6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 3        # At a time 3 features will be selected\n",
    "num_trees = 150\n",
    "model_r = RandomForestClassifier(n_estimators = num_trees, max_features = max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a00252b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(model_r, x, y, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72957628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.21462747778537"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87762ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bc596bc",
   "metadata": {},
   "source": [
    "## Adaboost Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dcd7541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold          # For getting samples of data\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48d50725",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = array[:,0:8]\n",
    "y = array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "674f0232",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits = 10, random_state = 7, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30ad5e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = 10                 # Here I have selected less no. of trees because as it is a sequential ensemble technique so it is anyhow time consuming and if we mention 100 trees and all it will be very tedious\n",
    "\n",
    "model_ad = AdaBoostClassifier(n_estimators = num_trees, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "910bebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(model_ad, x, y, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "120aa9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.69685577580314"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1431f3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d48c335",
   "metadata": {},
   "source": [
    "## Stacking Ensemble for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24c09c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold          # For getting samples of data\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier      # For stacking ensemble we will use voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3c1fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = array[:,0:8]\n",
    "y = array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "621b729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits = 10, random_state = 7, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12321936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As in stacking our base learners are going to be different so here we will create a list of estimators first.\n",
    "\n",
    "estimators = []\n",
    "model1 = LogisticRegression(max_iter = 500)\n",
    "estimators.append(('LogisticRegression',model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('DecisionTree',model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('SVC',model3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "057824eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Final model using the estimators\n",
    "\n",
    "model_stack = VotingClassifier(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d213e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(model_stack, x, y, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f99e891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.21633629528367"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb1c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
